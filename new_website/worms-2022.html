<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The 4th International Workshop on Reading Music Systems 2022</title>
    <link rel="stylesheet" href="assets/css/styles.css">
</head>
<body>
    <header>
        <h1>Elona Shatri</h1>
        <p>AI Researcher | Ethics Advocate | Music Technologist</p>
    </header>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="blogposts.html">Blogposts</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>
    <main>
        <section id="blogpost">
            <h2>The 4th International Workshop on Reading Music Systems 2022</h2>
            <article>
                <p>
                    The fourth edition of the International Workshop on Reading Music Systems (WoRMS) was held last Friday, offering another dynamic hybrid experience. Researchers and industry professionals in Optical Music Recognition (OMR) came together to explore the latest advancements and challenges in the field. This year’s workshop featured nine diverse papers spanning topics such as dataset challenges, deep learning innovations, and integration of language models, alongside an engaging keynote by Marie Chupeau (Magic LEMP).
                </p>
                <h3>Keynote: Advancing OMR with MaestrIA</h3>
                <p>
                    Marie Chupeau opened the workshop by presenting Magic LEMP's OMR solution, MaestrIA, developed for Newzik. She shared insights into their experiments with neural architectures for sequential, mask, and object detection approaches, highlighting the potential of score generation as an asset in OMR. Her discussion delved into the design process of their score generator, sparking interest and questions about how such systems might reshape music digitization.
                </p>
                <h3>Highlights from the Paper Sessions</h3>
                <h4>Session 1: Datasets and Training Challenges</h4>
                <ul>
                    <li>
                        <strong><a href="#">Challenging Sources: A New Dataset for OMR of Diverse 19th-Century Music Theory Examples</a></strong>  
                        — Fabian C. Moss and collaborators introduced a dataset targeting diverse 19th-century music theory materials, addressing the need for varied and challenging OMR training sets.
                    </li>
                    <li>
                        <strong><a href="#">CompIdNet: Sheet Music Composer Identification Using Deep Neural Networks</a></strong>  
                        — Dnyanesh Walwadkar and colleagues presented their work on composer identification through deep learning, adding a novel dimension to OMR.
                    </li>
                    <li>
                        <strong><a href="#">Obstacles with Synthesizing Training Data for OMR</a></strong>  
                        — Jiří Mayer and Pavel Pecina explored challenges in generating synthetic training data, identifying issues when bridging the gap between synthetic and real-world datasets.
                    </li>
                </ul>

                <h4>Session 2: Full-Page and Graph-Based OMR</h4>
                <ul>
                    <li>
                        <strong><a href="#">End-To-End Full-Page Optical Music Recognition of Monophonic Documents via Score Unfolding</a></strong>  
                        — Antonio Ríos-Vila and team proposed a full-page recognition pipeline leveraging a score unfolding mechanism for monophonic documents.
                    </li>
                    <li>
                        <strong><a href="#">End-to-End Graph Prediction for Optical Music Recognition</a></strong>  
                        — Carlos Garrido-Muñoz and collaborators discussed graph-based models, enabling efficient encoding of complex music notation relationships.
                    </li>
                    <li>
                        <strong><a href="#">Efficient Approaches for Notation Assembly in Optical Music Recognition</a></strong>  
                        — Carlos Penarrubia and co-authors presented techniques for efficiently assembling notations post-recognition, optimizing the final stages of the OMR pipeline.
                    </li>
                </ul>

                <h4>Session 3: Applications and Enhancements</h4>
                <ul>
                    <li>
                        <strong><a href="#">Computer-Assisted Measure Detection in a Music Score-Following Application</a></strong>  
                        — Eran Egozy and Ian Clester focused on integrating measure detection for applications in score-following, emphasizing real-time performance aids.
                    </li>
                    <li>
                        <strong><a href="#">Automated Transcription of Electronic Drumkits</a></strong>  
                        — Florent Jacquemard and team showcased their work on transcribing electronic drumkit performances, bridging electronic and traditional score representation.
                    </li>
                    <li>
                        <strong><a href="#">Improving Handwritten Music Recognition through Language Model Integration</a></strong>  
                        — Pau Torras and colleagues demonstrated how language models could enhance recognition accuracy, particularly for handwritten scores.
                    </li>
                </ul>
            </article>
        </section>
    </main>
    <footer>
        <p>© 2024 Elona Shatri. All rights reserved.</p>
    </footer>
</body>
</html>
