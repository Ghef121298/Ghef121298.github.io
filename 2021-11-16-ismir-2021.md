---
layout: post-default
---


<!-- ---
layout: post-default
title: Favourites at ISMIR2021 
date: 2021-11-16 10:03
category: conference
author: Elona Shatri
tags: [ismir2021, papers, workshops]
summary: This blogpost will be on my favourite papers, workshops, tutorials, talks on ISMIR2021. 
--- -->

This year's ISMIR was another peak point for the conference and the Music Information Retrieval (MIR) society. It has been amazing seeing how everyhting was desgined to work toward inclusivity and welcoming of new people to the field of MIR. Except for that, we all as MIR researchers look forward to ISMIR as the best place to showcase our work. 

I will now list some of my favourite papers and acvtivities, talks, initiatives on ISMIR2021. 


[ON THE INTEGRATION OF LANGUAGE MODELS INTO SEQUENCE TO SEQUENCE ARCHITECTURES FOR HANDWRITTEN MUSIC RECOGNITION](https://archives.ismir.net/ismir2021/paper/000086.pdf)


This paper explores the possibility of using Seq2Seq-based architecture to try to improve transcriptions. It focuses in handwritten sheet music given the challanges such scores present with the ambiguity of the handwritting and the decaying/artefacts on older sheets. The advantage of using such sequesnces mainly lies in the unavailibility of symbol-level bounding box information for training. 
An image of the score is treated as s equence of column vectors which is then fed into a CNN based on a VGG19 without the last max pooling layer. Then the encoder (bidirectional stack of GRUs), generates an intermediate representiation comprised as many features vectors as the convolutional networks (CNN). 
![Figure-1]({% link /assets/img/Dorico_Logo.png %})
After the encoder has processed the image the decoder recieves the generated hidden starte with the last poredicted token in the sequence which produces the next ourput token until a specisl end token is produced.
They first trained a LM with the original SM dataset, and then an updated version of the SM which comprised of the 66% of the tokens that are present in the HW set. They trained the Seq2Seq classifier with the unmodified SM for 30 epochs and then joined both models and trained them using Curriculum Learning strategy. Validation and test sets come from the HW set.  Parameters settings are shown in the image below.
![Figure-2]({% link /assets/img/parameters.png %})
For evaluation metrics Symbor Error Rate (SER) was used. Baseline results using BLSTM + CTC are 56% of SER and 31.79% for Seq2Seq. 
As a conclusion, LM seems to boost performance for handwritten sheet music recognition that is with the exsiting evaluation. It is however hard to tell how these models are keeping the structure and the musical meaningfulness. 


[AN EMPIRICAL EVALUATION OF END-TO-END POLYPHONIC OPTICAL MUSIC RECOGNITION](https://archives.ismir.net/ismir2021/paper/000020.pdf)

This work aims to provide with different formulation on how to tackle end-to-end polyphonic music recognition. To do so, they first provide with the workflow of creating a polyphonic dataset using MuseScore forum, and then formulations for end-to-end polyphonic OMR. These formulations are two different approaches, one looks at it as a multi-task binary classification while the other treats it as multi-sequence detection. They propose FlagDecoder and RNNDecoder respective to the aforementioned formulations. As for data annotations, they used a minimal symbol set sufficent to represent pitch and rhythm. They did not consider dynamics, ties, tuplets, staccatos, accents and other staff text. Only symbols used are barlines, time signatures, key signatures, clefs, and notes. They used the "advance position" encoding which adds '+' between sequesntial occurrences. Individual notes of chords are ordered 
from bottom to top. They select a subset of the MuseScore Polyphonic Dataset (MSPD) with a minimum of 41 symbols length, 1 measure, 2 voices and maximum of 679 symbol length, 8 measures and 4 voices. 
Architecturally speaking, models compared share the same structure of an encoder and decoder. The first one extracting features and give global context of the image encoding to each image slice, and the decoder uses the represenations created by the decoder and predict the symbols in the image slices. Encoding/decoding architecture is reused from prior work from Calvo-Zaragoza on monophonic scores. 
![Figure-3]({% link /assets/img/encoder.png %})
![Figure-4]({% link /assets/img/decoders.png %})
For evaluation metrics they used Pitch and Rhythm Symbol Error Rate (SER). 
SER = (I + D + S)/N.
While the FlagDecoder slightly imporves on the baseline, the RNNDecoder performs twice as well as the baseline. While such approacehes are crucial to move forward to polyphonic music recognition, this work is still very limited in recognising such scores. 


[UNSUPERVISED DOMAIN ADAPTATION FOR DOCUMENT ANALYSIS OF MUSIC SCORE IMAGES](https://archives.ismir.net/ismir2021/paper/000009.pdf)

As highlighted in multiple work in OMR, the challange of the missing annotated data for most of the datasets is very persistent, especially so for supervised learning. As in many other fields, this work tried to explore the possibility of using Domain Adaptation (DA) and tranfer knowledge from other domains for which labels are available. They combine DA based on adversarial training with Selectional Auto Encoders to define an unsupervised framework.  A framework processes the input images to classify each pixel into a set of possible categories—staff lines, notes, text and background. The architecture has an enoder where data are processed by a series of consecutive convolution and down-sampling layers, and a decoder, composed of convolutional and up-sampling layers. The output of the SAE will be a probabilistic map with one channel, in which the probability of each pixel belonigng to a layer is computed. However, such framework should be altered for when annotatated data are missing. This is when DA comes into place, where only domain S needs to have annotations. Using DA then the task si to adapt it to unlabeled data in domain T. 
![Figure-5]({% link /assets/img/DA-SAE.png %})
They use the EINSIEDELN, SALZINNES and CAPITAN corporas which are manually labeled. As metrics F1 meaure is used, reasoned with the imbalanced distribution of the classes. Adapting from domain Neumatic to the Mensural domain, DA improves F1 compared to prior work. While transferring knowledge from Mensural (domain S) to Neumatic (T domain) there are both slight improvement and reducing F1 score, depending on the sets used. This could come as domain invariant features are not being extracted by the network depending on the complexity of the datasets. 


[ARTIST SIMILARITY WITH GRAPH NEURAL NETWORKS](https://archives.ismir.net/ismir2021/paper/000043.pdf)

Makes use of Graph Convolutiona Neural Networks (GCNN) to add hierchical relationships to the artist similarity problem  using triplet loss. This combines the topology of a graph of artitst connections with content features to embed artists into vecotr space that encodes similarity. They also provide with OLGA dataset that contains 17673 artists with coontent-based features. Their findings show that such hybrid approach canbe even more effective than high-quality features to understand artist similarity. 
![Figure-5]({% link /assets/img/graph-network.png})


New initiatives:
    Lab Showcase

    A new and fantastic idea for this year’s ISMIR conference was the Lab Showcase chaired by my PhD colleague [Lele Liu](https://cheriell.github.io/). This activity featured virtual booths hosted by MIR research labs from around the world, C4DM had its fair share, introducing senior and junior researchers in its booth. Attendees were able to learn about ongoing research and labs would provide live chat slots to answer questions. This was a great opportunity to scout out potential degree programs, expand your network, and to get a feel for what current MIR researchers are working on.

    Necomer Initiative
    Coming to a new conference for the first time can be intimidating and overwhelming. At ISMIR this year, the Newcomer Initiatives Chairs have drawn on the past experiences of the MIR community to provide increased support to newcomers. The initiatives planned for the conference included a pair of special sessions on “Getting the most out of ISMIR 2021”, which follow up on a community survey and blog post on the subject published before the conference. The sessions were hosted by Newcomer Initiatives Chairs Nick Gang (Apple) and myself . Another new initiative was the creation of Newcomer Squads, which connected ISMIR veterans with groups of newcomers to answer questions, give advice, and offer support over the course of the conference week.


    Diversity & Inclusion
    he ISMIR 2021 conference takes a broad view of Diversity and Inclusion (D&I). Under the leadership of the conference D&I Chairs, in collaboration with the organizing team at large, ISMIR 2021 offers a variety of initiatives intended to make the conference a positive, welcoming, and supportive environment for a diverse range of presenters and attendees. Notably, this year’s virtual conference format, combined with generous sponsor support, has enabled an unprecedented level of financial support to cover registration and childcare costs. Registration waivers were made available to students, women and other underrepresented minorities in MIR, attendees from low-income countries, presenters in the “New-to-ISMIR” late-breaking/demo track, and unaffiliated attendees. All attendees were additionally eligible to apply for childcare grants. The ISMIR 2021 organizers also worked together to write a number of blog posts aimed to decrease barriers for participation in the MIR research community, for example, by offering insights into preparing and reviewing scientific submissions. Finally, the ISMIR conference Code of Conduct remains in place for this year’s virtual format. 
