I"p<h1 id="doremi---data-collection-lifecycle-document">DoReMi - Data Collection Lifecycle Document</h1>

<p>This documents the lifecycle of the DOREMI dataset. DOReMi is a dataset that contains data related to OMR research. DOReMi is a product of collaborative work between Steinberg (Dorico team) and QMUL (Elona Shatri and George Fazekas). This dataset aims to fill in the existing gaps in OMR research. It is part of a larger research question, whether deep learning can assist theOMR field.  What sets DOReMi aside from the other datasets is the richness of data. Given that this dataset is generated using Dorico (a music notation software from Steinberg), we had the chance to grab more musical information on it, but also different types of data. Using Dorico we can generate 5 types of data that could possibly be used in different steps of OMR. These data are images of scores (binary or colour), the musicXML file, XML files with metadata such as bounding boxes of each object together with musical information, which will be explained in detail later on, and as part of our dataset we can utilize the midi audio file which can be later used for transcription as well.</p>

<h2 id="discovery-and-planning"><a href="#discovery-and-planning">Discovery and Planning</a></h2>

<h3 id="data-type-and-format"><a href="#Data-type-and-format">Data type and format</a></h3>
<ul>
  <li>Dorico project</li>
  <li><a href="#MusicXML">MusicXML</a></li>
  <li><a href="#OMR-metadata">OMR metadata</a></li>
  <li><a href="#Images-of-scores">Images of scores</a></li>
  <li><a href="#MIDI">MIDI</a></li>
  <li><a href="">Combining DOReMi with Muscima++ and Deepscores</a></li>
</ul>

<h2 id="initial-data-collection"><a href="">Initial Data Collection</a></h2>
<h2 id="data-preparation-and-analysis"><a href="">Data Preparation and analysis</a></h2>
<h2 id="publication-and-sharing"><a href="">Publication and Sharing</a></h2>
<h2 id="long-term-management"><a href="">Long-term Management</a></h2>

<h2 id="-discovery-and-planning-"><a href="#discovery-and-planning"> Discovery and Planning </a></h2>

<p>In this section, I will explain the data types and formats we have decided to use.</p>

<h3 id="-data-type-and-format-"><a href="#Data-type-and-format"> Data type and format </a></h3>

<p>This dataset has the following six types of data:</p>

<ul>
  <li><a href="#dorico-project">Dorico project</a></li>
  <li><a href="#MusicXML">MusicXML</a></li>
  <li><a href="#OMR-metadata">OMR metadata</a></li>
  <li><a href="#Images-of-scores">Images of scores</a></li>
  <li><a href="#MIDI">MIDI</a></li>
  <li><a href="#MEI">Music Encoding Initiative (MEI)</a></li>
</ul>

<p>The following respective data formats:</p>
<ul>
  <li>Dorico</li>
  <li>MusicXML</li>
  <li>XML</li>
  <li>PNG</li>
  <li>MIDI</li>
  <li>MEI</li>
</ul>

<p>Let’s start by explaining each one of the data types and what they contain:</p>

<p><a href="#dorico-project"> Dorico project </a>
<img src="/assets/img/Dorico_Logo.png" alt="Dorico-project" /></p>

<p>When saving the scores in Dorico, it uses the .dorico file format, which is the project type. Saving the projects is really important for the lifecycle since it allows us to use the same layout settings if we later want to generate other data or change.</p>

<p><a href="#MusicXML">  MusicXML </a></p>

<p>MusicXML is widely known and used data format in music notation which uses the XML file format. MusicXML allows interchangeability between different scorewriters. Dorico can export the projects to MusicXML. The extension for these files is .xml. 
More on how these files can be exported check <a href="https://steinberg.help/dorico_pro/v3/en/dorico/topics/project_file_handling/project_file_handling_musicxml_files_exporting_t.html"> here </a>
<img src="/assets/img/musicXML.png" alt="MusicXML-example" /></p>

<p><a href="#OMR-metadata"> OMR metadata </a></p>

<p>OMR metadata are the files that incorporate most of the information needed for OMR practitces. These files include visual information, coordinates, bounding boxes, pixel information and furthermore musical information such as duration beats, onset beats, pitch octave, midi pitch note, normalized pitch step and the dorico event id depending on the class of the object.</p>

<p>Depending on the task the dataset includes both parsed and unparsed XML files. If the dataset is to be used only for object detection or instance segmentation the parsed files are divided by page, corresponding to an image respective to the actual page. These files hold information on the bounding boxes and pixel mask information.</p>

<p><img src="/assets/img/unparsed-xml.png" alt="unparsed-xml" /></p>

<p><img src="/assets/img/notehead.png" alt="notehead" /></p>

<p><img src="/assets/img/staff-line.png" alt="staffline" /></p>

<p><a href="#Images-of-scores"> OMR metadata </a></p>

<p>Given that each project can have one or more pages, we use the mono png export from Dorico at 300 DPI. Each image is named after the OMR metadata xml file, with the number suffix, starting 001. Images are of dimension 2475 × 3504 pixels and are binarised. An example of an image is given below.</p>

<p><a href="#MIDI"> MIDI </a></p>

<p>MIDI files are exported directly from Dorico.</p>

<p><a href="#MEI"> Music Encoding Initiative (MEI) </a></p>

<h2 id="-combining-doremi-with-muscima-and-deepscores-"><a href="#combining"> Combining DOReMi with Muscima++ and Deepscores </a></h2>

<p><a href="./">back</a></p>
:ET