<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The 5th International Workshop on Reading Music Systems 2023</title>
    <link rel="stylesheet" href="assets/css/styles.css">
</head>
<body>
    <header>
        <h1>Elona Shatri</h1>
        <p>AI Researcher | Ethics Advocate | Music Technologist</p>
    </header>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="blogposts.html">Blogposts</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>
    <main>
        <section id="blogpost">
            <h2>The 5th International Workshop on Reading Music Systems 2023</h2>
            <article>
                <p>
                    The 5th International Workshop on Reading Music Systems (WoRMS) took place on November 4th, 2023, in Milan, Italy, offering both on-site and remote participation. This year’s workshop showcased a range of cutting-edge research in Optical Music Recognition (OMR), including advancements in medieval music manuscripts, handwritten music synthesis, and few-shot learning. The program featured three engaging paper sessions and a thought-provoking keynote by Werner Goebl, emphasizing community-driven solutions to perfect music score corpora.
                </p>
                <h3>Keynote: Perfecting Music Scores with Crowd-Sourced Validation</h3>
                <p>
                    Werner Goebl from the University of Music and Performing Arts Vienna delivered the keynote titled "The Final Stretch of OMR: Perfecting Music Score Corpora with Browser-Based Editing and Validation." Goebl introduced <em>mei-friend</em>, a browser-based editing and validation interface that facilitates community-driven corrections to OMR-generated scores. This innovative tool juxtaposes source score images with their digital renderings, enabling crowdsourced validation to ensure pristine accuracy. The keynote sparked discussions on how decentralized, open systems can contribute to a FAIR (Findable, Accessible, Interoperable, and Reusable) digital music ecosystem.
                </p>
                <h3>Highlights from the Paper Sessions</h3>
                <h4>Session 1: Historical and Multicultural Perspectives</h4>
                <ul>
                    <li><strong>Optical Music Recognition Workflow for Medieval Music Manuscripts</strong> — Ichiro Fujinaga and Gabriel Vigliensoni explored workflows tailored to the unique challenges of medieval manuscripts, emphasizing the importance of preserving historical notations.</li>
                    <li><strong>The Suzipu Musical Annotation Tool</strong> — Tristan Repolusk and Eduardo Veas introduced <em>Suzipu</em>, a tool designed to create machine-readable datasets for ancient Chinese music, bridging gaps in cultural heritage digitization.</li>
                    <li><strong>The OmniOMR Project</strong> — Jan Hajič, jr., and collaborators presented a comprehensive framework for OMR, addressing multi-lingual and multi-modal requirements for diverse music scores.</li>
                    <li><strong>Towards Music Notation and Lyrics Alignment</strong> — Juan Carlos Martinez-Sevilla and Francisco J. Castellanos shared a case study on aligning notation and lyrics in Gregorian chants, advancing research in music-text alignment.</li>
                </ul>

                <h4>Session 2: Data Generation and Enhancement</h4>
                <ul>
                    <li><strong>Symbol Generation via Autoencoders for Handwritten Music Synthesis</strong> — Jonáš Havelka and team showcased how autoencoders can generate handwritten music symbols, contributing to realistic data synthesis.</li>
                    <li><strong>Towards Artificially Generated Handwritten Sheet Music Datasets</strong> — Pranjali Hande and collaborators presented methods for generating artificial datasets, addressing the scarcity of annotated data in OMR.</li>
                    <li><strong>Improving Sheet Music Recognition with Data Augmentation and Image Enhancement</strong> — Zihui Zhang and colleagues discussed innovative techniques for improving OMR accuracy, leveraging data augmentation and image preprocessing.</li>
                </ul>

                <h4>Session 3: Few-Shot and End-to-End Learning</h4>
                <ul>
                    <li><strong>Rotations Are All You Need: A Generic Method for End-To-End OMR</strong> — Antonio Ríos-Vila introduced a novel approach using rotations to simplify and improve end-to-end OMR pipelines.</li>
                    <li><strong>Few-Shot Music Symbol Classification via Self-Supervised Learning</strong> — María Alfaro-Contreras presented a method for classifying music symbols with minimal training data, leveraging self-supervised learning.</li>
                    <li><strong>Few-Shot Learning for Layout Analysis of Music Scores</strong> — Francisco J. Castellanos and team conducted a preliminary study on applying few-shot learning to the layout analysis of complex music scores.</li>
                </ul>
            </article>
        </section>
    </main>
    <footer>
        <p>© 2024 Elona Shatri. All rights reserved.</p>
    </footer>
</body>
</html>
