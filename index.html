<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Elona Shatri - Portfolio</title>
    <link rel="stylesheet" href="assets/css/styles.css">
</head>

<body>
    <header>
        <!-- <img src="assets/images/headshot_elona.jpeg" alt="Elona Shatri" style="width:150px; border-radius:50%;"> -->
        <h1>Elona Shatri</h1>
        <p>AI Researcher | Ethics Advocate | Music Technologist</p>

    </header>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="blogposts.html">Blogposts</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>
    <main>
        <section id="home" style="display:flex; align-items:center; gap:20px;">
            <img src="assets/images/headshot_elona.jpeg" alt="Elona Shatri"  
                 style="width:120px; border-radius:50%;">
            <div>
                <h2>Welcome</h2>
                <p>Welcome to my portfolio! I explore the intersections of Artificial Intelligence, ethics, and music technology. Here, you’ll find my research, projects, and datasets.</p>
            </div>
        </section>
        
        <section id="about">
            <h2>About</h2>
            <p>
                I'm a PhD candidate at the UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM). I am part of the Centre for Digital Music (C4DM) research group at Queen Mary University of London. 
                
                My research interests include Optical Music Recognition as well as other MIR-related subfields. My goal is to have computers read sheet music computationally. I started working on this problem in September 2019 when I was granted the studentship from QMUL and Steinberg GmBH, with whom we collaborate closely. 
                
                I am also the founder and a steering committee member of the <a href="https://www.qmul.ac.uk/ai-and-ethics/" target="_blank">QMUL AI and Ethics Research Group</a>. This group critically examines the ethical dimensions of AI, with a focus on ensuring responsible and inclusive AI applications. The group organizes interdisciplinary seminars, collaborative workshops, and research projects that explore topics such as fairness, accountability, transparency, and the societal implications of AI technologies.
                
            
            </p>
        </section>
        
        <section id="research">
            <h2>Research Interests</h2>
            <p><strong>Optical Music Recognition:</strong> Enhancing information retrieval in OMR systems through new methodologies.</p>
            <p><strong>Ethics in AI:</strong> Exploring ethical considerations in AI, focusing on accountability, fairness, and transparency in applications across various domains.</p>
            <h3>Published Research</h3>
            <ul>
                <li><a href="https://arxiv.org/abs/2408.15002" target="_blank">Knowledge Discovery in Optical Music Recognition: Enhancing Information Retrieval with Instance Segmentation, in Proceedings of the 16th International Conference on Knowledge Discovery and Information Retrieval, Best Student Paper Award, 2024.</a></li>
                <li><a href="https://arxiv.org/abs/2411.16405" target="_blank">Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN, IEEE Big Data 2024 2nd Workshop on AI Music Generation (AIMG 2024)), 2024.</a></li>
                <li><a href="https://arxiv.org/abs/2411.16408" target="_blank">Low-Data Classification of Historical Music Manuscripts: A Few-Shot Learning Approach, The Sixth IEEE International Conference on Image Processing Applications and Systems, 2024</a></li>
                <li><a href="https://arxiv.org/abs/2411.15741" target="_blank">Crafting Handwritten Notations: Towards Sheet Music Generation, in 6th International Workshop on Reading Music Systems, 2024</a></li>
                <li><a href="https://sites.google.com/view/worms2021/home" target="_blank">DoReMi: First glance at a universal OMR dataset, in 3rd International Workshop on Reading Music Systems, 2021</a></li>
                <li><a href="https://arxiv.org/pdf/2211.13285.pdf#page=10" target="_blank">CompldNet: Sheet Music Composer Identification using Deep Neural Network, in 4th International Workshop on Reading Music Systems, 2022</a></li>
                <li><a href="https://arxiv.org/pdf/2311.04091.pdf#page=26" target="_blank">Towards Artificially Generated Handwritten Sheet Music Datasets, in 5th International Workshop on Reading Music Systems, 2023</a></li>
                <li><a href="https://arxiv.org/pdf/2311.04091.pdf#page=32" target="_blank">Improving Sheet Music Recognition using Data Augmentation and Image Enhancement, in 5th International Workshop on Reading Music Systems, 2023</a></li>
                <li><a href="https://www.tenor-conference.org/proceedings/2020/23_Shatri_tenor20.pdf" target="_blank">Optical Music Recogntion: State of the Art and Major Challenges, in The International Conference on Technologies for Music Notation and Representation, 2020</a></li>
                <li><a href="https://arxiv.org/abs/2408.14340" target="_blank">Foundation Models for Music: A Survey</a></li>
            </ul>
            <h3>Proceedings Editor</h3>
            <ul>
                <li><a href="https://arxiv.org/abs/2211.13285" target="_blank">Proceedings of the 4th International Workshop on Reading Music Systems</a></li>
                <li><a href="https://arxiv.org/pdf/2311.04091" target="_blank">Proceedings of the 5th International Workshop on Reading Music Systems</a></li>
                <li><a href="https://arxiv.org/abs/2411.15741" target="_blank">Proceedings of the 6th International Workshop on Reading Music Systems</a></li>
            </ul>
            <h3>Presentations</h3>
            <ul>
                <li><a href="https://www.qmul.ac.uk/deri/news--events-/featured-event-policy-forum-of-the-harvard-data-science-review---futureshock/" target="_blank">E. Shatri, “Crafting responsive assessments of AI and tech futures (CREAATIF),” Poster presented at the Policy Forum of the Harvard Data Science Review’s Special Issue on Generative AI (GenAI), June 2024.</a></li>
                <li><a href="https://bloomsburyfestival.org.uk/events/ai-music-lecture-symposium/" target="_blank">E. Shatri, “Navigating the intersection of AI and creativity: A case study of musicians in the age of GenAI,” Presentation at the AI & Music Lecture Symposium and Jam, Bloomsbury Festival, October 2024.</a></li>
                <li><a href="https://sites.google.com/view/worms2024/program" target="_blank">Enhancing Handwritten Music Sheet Datasets Using Generative Adversarial Networks, the 6th International Workshop on Reading Music Systems</a></li>
            </ul>
        </section>
        <section id="projects">
            <h2>Projects and Datasets</h2>
            <h3><a href="https://www.gov.uk/government/news/uk-and-qatar-launch-project-to-boost-artificial-intelligence-collaboration" target="_blank">Research Assistant (October 2024-): UK and Qatar joint Artificial Intelligence (AI) research commission</a></h3>
            <p>The UK and Qatar joint Artificial Intelligence (AI) research commission seeks to establish a roadmap for UK-Qatar collaboration on AI that will benefit both countries.</p>
            <h3><a href="https://www.turing.ac.uk/research/research-projects/crafting-responsive-assessments-ai-tech-impacted-futures-creaatif" target="_blank">Research Assistant (February 2024-): Crafting Responsive Assessments of AI & Tech-Impacted Futures (CREAATIF)</a></h3>
            <p>Crafting Responsive Assessments of AI & Tech-Impacted Futures (CREAATIF) aims to bring the voices of creative workers into the foreground, particularly within policy guidance for the UK labour context. </p>
            <h3><a href="link-to-doremi-project" target="_blank">DoReMi - Data Collection Lifecycle</a></h3>
            <p>The DoReMi dataset documents the lifecycle of Optical Music Recognition (OMR) data. It serves as a resource for advancing research in OMR systems.</p>
        </section>        
        <section id="blogposts">
            <a href="blogposts.html" class="btn">View All Blogposts</a>
    
            <h2>Blogposts and News</h2>
            <h3><a href="dummy-link-to-worms-2024" target="_blank">The 6th International Workshop on Reading Music Systems 2024</a></h3>
            <p>
                The 6th International Workshop on Reading Music Systems (WoRMS) took place virtually, bringing together researchers and practitioners from across the globe to discuss the latest developments in Optical Music Recognition (OMR). This year’s workshop featured three paper sessions, panels, and an insightful keynote by David Rizo, providing a comprehensive exploration of the state of OMR research and its real-world applications.
            </p>
            <h3><a href="dummy-link-to-worms-2023" target="_blank">The 5th International Workshop on Reading Music Systems 2023</a></h3>
            <p>
                The 5th International Workshop on Reading Music Systems (WoRMS) took place on November 4th, 2023, in Milan, Italy, offering both on-site and remote participation. This year’s workshop showcased a range of cutting-edge research in Optical Music Recognition (OMR), including advancements in medieval music manuscripts, handwritten music synthesis, and few-shot learning.
            </p>
            <h3><a href="dummy-link-to-worms-2022" target="_blank">The 4th International Workshop on Reading Music Systems 2022</a></h3>
            <p>
                The fourth edition of the International Workshop on Reading Music Systems (WoRMS) was held last Friday, offering another dynamic hybrid experience. Researchers and industry professionals in Optical Music Recognition (OMR) came together to explore the latest advancements and challenges in the field.
            </p>
            <h3><a href="dummy-link-to-omr-state-of-the-art" target="_blank">Optical Music Recognition: State of the Art and Major Challenges</a></h3>
            <p>
                Recently, I published my very first paper summarizing the state of the art and open challenges in Optical Music Recognition (OMR). The paper discusses paradigm shifts, evolving methodologies, and potential future directions for the field.
            </p>
            <h3><a href="dummy-link-to-gan-review" target="_blank">A Review on Generative Adversarial Networks</a></h3>
            <p>
                An exploration of how GANs have revolutionized machine learning by bridging generative and discriminative networks. The blog discusses their history, key advancements, and their implications in fields ranging from art to computer vision.
            </p>
        </section>
        
        <section id="contact">
            <h2>Contact</h2>
            <p>Feel free to reach out via email or connect with me on LinkedIn for collaborations and inquiries.</p>
            <ul>
                <li>Email: <a href="mailto:e.shatril@qmul.ac.uk">e.shatri@qmul.ac.uk</a></li>
                <li>LinkedIn: <a href="https://www.linkedin.com/in/elona-shatri-080b33b5/" target="_blank">Elona Shatri</a></li>
            </ul>
        </section>
    </main>
    <footer>
        <p>© 2024 Elona Shatri. All rights reserved.</p>
    </footer>
</body>
</html>
